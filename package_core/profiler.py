"""
æ€§èƒ½åˆ†ææ¨¡å— - PackageWizard æ—¶é—´ç»Ÿè®¡ç³»ç»Ÿ

ç”¨äºç»Ÿè®¡ï¼š
1. æ­¥éª¤ç”¨æ—¶ - å„ä¸»è¦å¤„ç†æ­¥éª¤çš„æ‰§è¡Œæ—¶é—´
2. å‡½æ•°ç”¨æ—¶ - å‡½æ•°è°ƒç”¨æ¬¡æ•°å’Œæ€»æ—¶é—´
3. æ¨¡å‹æ¨ç†æ—¶é—´ - DETR/YOLO/DBNet/SVTRç­‰æ¨¡å‹çš„æ¨ç†æ—¶é—´
4. å‡½æ•°è°ƒç”¨æ ˆåˆ†æ - è°ƒç”¨å±‚çº§å’Œçƒ­ç‚¹å‡½æ•°è¯†åˆ«
5. æ¨¡å‹æ¨ç†è¯¦ç»†æŒ‡æ ‡ - ååé‡ã€å†…å­˜ä½¿ç”¨ç­‰

ä½¿ç”¨æ–¹æ³•ï¼š
    from package_core.profiler import profiler, step_timer, func_timer, model_timer

    # æ­¥éª¤è®¡æ—¶
    with step_timer("PDFé¢„å¤„ç†"):
        do_preprocess()

    # å‡½æ•°è£…é¥°å™¨
    @func_timer
    def my_function():
        pass

    # æ¨¡å‹æ¨ç†è®¡æ—¶ï¼ˆå¸¦è¯¦ç»†ä¿¡æ¯ï¼‰
    with model_timer("DETR", {"input_size": "640x640", "batch_size": 1}):
        model.predict()

    # å‡½æ•°è°ƒç”¨æ ˆè¿½è¸ª
    @call_tracker
    def traced_function():
        pass

    # ç”ŸæˆæŠ¥å‘Š
    profiler.generate_report("performance_report.json")
"""

import time
import json
import threading
import traceback
import sys
from contextlib import contextmanager
from functools import wraps
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field, asdict
from datetime import datetime
from collections import defaultdict
import os


@dataclass
class TimingRecord:
    """å•æ¬¡è®¡æ—¶è®°å½•"""
    name: str
    duration: float  # ç§’
    timestamp: str
    category: str  # 'step', 'function', 'model'
    extra_info: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AggregatedStats:
    """èšåˆç»Ÿè®¡ä¿¡æ¯"""
    name: str
    category: str
    call_count: int = 0
    total_time: float = 0.0
    min_time: float = float('inf')
    max_time: float = 0.0
    avg_time: float = 0.0

    def update(self, duration: float):
        self.call_count += 1
        self.total_time += duration
        self.min_time = min(self.min_time, duration)
        self.max_time = max(self.max_time, duration)
        self.avg_time = self.total_time / self.call_count


@dataclass
class ModelInferenceStats:
    """æ¨¡å‹æ¨ç†è¯¦ç»†ç»Ÿè®¡"""
    model_name: str
    call_count: int = 0
    total_time: float = 0.0
    min_time: float = float('inf')
    max_time: float = 0.0
    avg_time: float = 0.0
    # è¯¦ç»†æŒ‡æ ‡
    total_samples: int = 0  # å¤„ç†çš„æ ·æœ¬æ€»æ•°
    throughput: float = 0.0  # æ ·æœ¬/ç§’
    preprocess_time: float = 0.0  # é¢„å¤„ç†æ—¶é—´
    inference_time: float = 0.0  # çº¯æ¨ç†æ—¶é—´
    postprocess_time: float = 0.0  # åå¤„ç†æ—¶é—´
    input_sizes: List[str] = field(default_factory=list)  # è¾“å…¥å°ºå¯¸è®°å½•

    def update(self, duration: float, batch_size: int = 1,
               preprocess: float = 0.0, inference: float = 0.0,
               postprocess: float = 0.0, input_size: str = None):
        self.call_count += 1
        self.total_time += duration
        self.min_time = min(self.min_time, duration)
        self.max_time = max(self.max_time, duration)
        self.avg_time = self.total_time / self.call_count
        self.total_samples += batch_size
        self.throughput = self.total_samples / self.total_time if self.total_time > 0 else 0
        self.preprocess_time += preprocess
        self.inference_time += inference
        self.postprocess_time += postprocess
        if input_size and input_size not in self.input_sizes:
            self.input_sizes.append(input_size)


@dataclass
class FunctionCallRecord:
    """å‡½æ•°è°ƒç”¨è®°å½•ï¼ˆåŒ…å«è°ƒç”¨æ ˆï¼‰"""
    func_name: str
    duration: float
    timestamp: str
    caller: str  # è°ƒç”¨è€…å‡½æ•°å
    call_stack: List[str]  # å®Œæ•´è°ƒç”¨æ ˆ
    args_info: str = ""  # å‚æ•°æ‘˜è¦ä¿¡æ¯


class CallGraphNode:
    """è°ƒç”¨å›¾èŠ‚ç‚¹"""
    def __init__(self, name: str):
        self.name = name
        self.call_count = 0
        self.total_time = 0.0
        self.self_time = 0.0  # è‡ªèº«è€—æ—¶ï¼ˆæ’é™¤å­è°ƒç”¨ï¼‰
        self.children: Dict[str, 'CallGraphNode'] = {}
        self.callers: Dict[str, int] = {}  # è°ƒç”¨è€… -> è°ƒç”¨æ¬¡æ•°

    def add_call(self, duration: float, caller: str = None):
        self.call_count += 1
        self.total_time += duration
        if caller:
            self.callers[caller] = self.callers.get(caller, 0) + 1

    def to_dict(self) -> Dict:
        return {
            'name': self.name,
            'call_count': self.call_count,
            'total_time': round(self.total_time, 4),
            'self_time': round(self.self_time, 4),
            'avg_time': round(self.total_time / self.call_count, 4) if self.call_count > 0 else 0,
            'callers': self.callers,
            'children': [child.to_dict() for child in self.children.values()]
        }


class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨ä¸»ç±»"""

    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self._initialized = True

        self.records: List[TimingRecord] = []
        self.stats: Dict[str, AggregatedStats] = {}
        self.step_stack: List[str] = []  # ç”¨äºåµŒå¥—æ­¥éª¤
        self.session_start: Optional[float] = None
        self.session_info: Dict[str, Any] = {}
        self._lock = threading.Lock()
        self.enabled = True

        # æ–°å¢ï¼šæ¨¡å‹æ¨ç†è¯¦ç»†ç»Ÿè®¡
        self.model_stats: Dict[str, ModelInferenceStats] = {}
        # æ–°å¢ï¼šå‡½æ•°è°ƒç”¨è®°å½•
        self.function_calls: List[FunctionCallRecord] = []
        # æ–°å¢ï¼šè°ƒç”¨å›¾
        self.call_graph: Dict[str, CallGraphNode] = {}
        # æ–°å¢ï¼šå½“å‰è°ƒç”¨æ ˆï¼ˆç”¨äºè¿½è¸ªåµŒå¥—è°ƒç”¨ï¼‰
        self._call_stack: List[str] = []
        # æ–°å¢ï¼šçƒ­ç‚¹å‡½æ•°é˜ˆå€¼
        self.hotspot_threshold = 0.05  # å æ€»æ—¶é—´5%ä»¥ä¸Šè§†ä¸ºçƒ­ç‚¹

    def start_session(self, info: Optional[Dict[str, Any]] = None):
        """å¼€å§‹ä¸€ä¸ªæ–°çš„åˆ†æä¼šè¯"""
        self.records = []
        self.stats = {}
        self.step_stack = []
        self.session_start = time.time()
        self.session_info = info or {}
        self.session_info['start_time'] = datetime.now().isoformat()
        # é‡ç½®æ–°å¢çš„ç»Ÿè®¡
        self.model_stats = {}
        self.function_calls = []
        self.call_graph = {}
        self._call_stack = []

    def end_session(self):
        """ç»“æŸå½“å‰ä¼šè¯"""
        if self.session_start:
            self.session_info['end_time'] = datetime.now().isoformat()
            self.session_info['total_duration'] = time.time() - self.session_start

    def record(self, name: str, duration: float, category: str,
               extra_info: Optional[Dict[str, Any]] = None):
        """è®°å½•ä¸€æ¬¡è®¡æ—¶"""
        if not self.enabled:
            return

        with self._lock:
            record = TimingRecord(
                name=name,
                duration=duration,
                timestamp=datetime.now().isoformat(),
                category=category,
                extra_info=extra_info or {}
            )
            self.records.append(record)

            # æ›´æ–°ç»Ÿè®¡
            key = f"{category}:{name}"
            if key not in self.stats:
                self.stats[key] = AggregatedStats(name=name, category=category)
            self.stats[key].update(duration)

    def record_model_inference(self, model_name: str, duration: float,
                               batch_size: int = 1,
                               preprocess_time: float = 0.0,
                               inference_time: float = 0.0,
                               postprocess_time: float = 0.0,
                               input_size: str = None,
                               extra_info: Optional[Dict[str, Any]] = None):
        """è®°å½•æ¨¡å‹æ¨ç†ï¼ˆå¸¦è¯¦ç»†ä¿¡æ¯ï¼‰"""
        if not self.enabled:
            return

        with self._lock:
            # è®°å½•åˆ°é€šç”¨è®°å½•
            info = extra_info or {}
            info.update({
                'batch_size': batch_size,
                'preprocess_time': preprocess_time,
                'inference_time': inference_time,
                'postprocess_time': postprocess_time,
                'input_size': input_size
            })

            record = TimingRecord(
                name=model_name,
                duration=duration,
                timestamp=datetime.now().isoformat(),
                category='model',
                extra_info=info
            )
            self.records.append(record)

            # æ›´æ–°é€šç”¨ç»Ÿè®¡
            key = f"model:{model_name}"
            if key not in self.stats:
                self.stats[key] = AggregatedStats(name=model_name, category='model')
            self.stats[key].update(duration)

            # æ›´æ–°æ¨¡å‹è¯¦ç»†ç»Ÿè®¡
            if model_name not in self.model_stats:
                self.model_stats[model_name] = ModelInferenceStats(model_name=model_name)
            self.model_stats[model_name].update(
                duration=duration,
                batch_size=batch_size,
                preprocess=preprocess_time,
                inference=inference_time,
                postprocess=postprocess_time,
                input_size=input_size
            )

    def record_function_call(self, func_name: str, duration: float,
                             caller: str = None, call_stack: List[str] = None,
                             args_info: str = ""):
        """è®°å½•å‡½æ•°è°ƒç”¨ï¼ˆå¸¦è°ƒç”¨æ ˆï¼‰"""
        if not self.enabled:
            return

        with self._lock:
            # è®°å½•å‡½æ•°è°ƒç”¨
            record = FunctionCallRecord(
                func_name=func_name,
                duration=duration,
                timestamp=datetime.now().isoformat(),
                caller=caller or "unknown",
                call_stack=call_stack or [],
                args_info=args_info
            )
            self.function_calls.append(record)

            # æ›´æ–°é€šç”¨ç»Ÿè®¡
            key = f"function:{func_name}"
            if key not in self.stats:
                self.stats[key] = AggregatedStats(name=func_name, category='function')
            self.stats[key].update(duration)

            # æ›´æ–°è°ƒç”¨å›¾
            if func_name not in self.call_graph:
                self.call_graph[func_name] = CallGraphNode(func_name)
            self.call_graph[func_name].add_call(duration, caller)

            # æ›´æ–°è°ƒç”¨è€…çš„children
            if caller and caller in self.call_graph:
                if func_name not in self.call_graph[caller].children:
                    self.call_graph[caller].children[func_name] = self.call_graph[func_name]

    def push_call_stack(self, func_name: str):
        """å…¥æ ˆï¼šè®°å½•å½“å‰è°ƒç”¨"""
        self._call_stack.append(func_name)

    def pop_call_stack(self) -> Optional[str]:
        """å‡ºæ ˆï¼šå¼¹å‡ºå½“å‰è°ƒç”¨"""
        if self._call_stack:
            return self._call_stack.pop()
        return None

    def get_current_caller(self) -> Optional[str]:
        """è·å–å½“å‰è°ƒç”¨è€…"""
        if len(self._call_stack) >= 1:
            return self._call_stack[-1]
        return None

    def get_call_stack(self) -> List[str]:
        """è·å–å½“å‰è°ƒç”¨æ ˆå‰¯æœ¬"""
        return self._call_stack.copy()

    def get_step_stats(self) -> List[Dict]:
        """è·å–æ­¥éª¤ç»Ÿè®¡"""
        return [
            {
                'name': s.name,
                'call_count': s.call_count,
                'total_time': round(s.total_time, 4),
                'avg_time': round(s.avg_time, 4),
                'min_time': round(s.min_time, 4) if s.min_time != float('inf') else 0,
                'max_time': round(s.max_time, 4),
            }
            for key, s in self.stats.items() if s.category == 'step'
        ]

    def get_function_stats(self) -> List[Dict]:
        """è·å–å‡½æ•°ç»Ÿè®¡"""
        result = [
            {
                'name': s.name,
                'call_count': s.call_count,
                'total_time': round(s.total_time, 4),
                'avg_time': round(s.avg_time, 4),
                'min_time': round(s.min_time, 4) if s.min_time != float('inf') else 0,
                'max_time': round(s.max_time, 4),
            }
            for key, s in self.stats.items() if s.category == 'function'
        ]
        # æŒ‰æ€»æ—¶é—´é™åºæ’åº
        return sorted(result, key=lambda x: x['total_time'], reverse=True)

    def get_model_stats(self) -> List[Dict]:
        """è·å–æ¨¡å‹æ¨ç†ç»Ÿè®¡"""
        result = [
            {
                'name': s.name,
                'call_count': s.call_count,
                'total_time': round(s.total_time, 4),
                'avg_time': round(s.avg_time, 4),
                'min_time': round(s.min_time, 4) if s.min_time != float('inf') else 0,
                'max_time': round(s.max_time, 4),
            }
            for key, s in self.stats.items() if s.category == 'model'
        ]
        return sorted(result, key=lambda x: x['total_time'], reverse=True)

    def get_model_detailed_stats(self) -> List[Dict]:
        """è·å–æ¨¡å‹æ¨ç†è¯¦ç»†ç»Ÿè®¡ï¼ˆåŒ…å«ååé‡ã€é¢„å¤„ç†/æ¨ç†/åå¤„ç†è€—æ—¶åˆ†è§£ï¼‰"""
        result = []
        for name, stats in self.model_stats.items():
            result.append({
                'name': name,
                'call_count': stats.call_count,
                'total_time': round(stats.total_time, 4),
                'avg_time': round(stats.avg_time, 4),
                'min_time': round(stats.min_time, 4) if stats.min_time != float('inf') else 0,
                'max_time': round(stats.max_time, 4),
                'total_samples': stats.total_samples,
                'throughput': round(stats.throughput, 2),  # æ ·æœ¬/ç§’
                'preprocess_time': round(stats.preprocess_time, 4),
                'inference_time': round(stats.inference_time, 4),
                'postprocess_time': round(stats.postprocess_time, 4),
                'input_sizes': stats.input_sizes,
                # è®¡ç®—å„é˜¶æ®µå æ¯”
                'preprocess_pct': round(stats.preprocess_time / stats.total_time * 100, 1) if stats.total_time > 0 else 0,
                'inference_pct': round(stats.inference_time / stats.total_time * 100, 1) if stats.total_time > 0 else 0,
                'postprocess_pct': round(stats.postprocess_time / stats.total_time * 100, 1) if stats.total_time > 0 else 0,
            })
        return sorted(result, key=lambda x: x['total_time'], reverse=True)

    def get_function_call_analysis(self) -> Dict:
        """è·å–å‡½æ•°è°ƒç”¨åˆ†æï¼ˆåŒ…å«è°ƒç”¨å…³ç³»å’Œçƒ­ç‚¹è¯†åˆ«ï¼‰"""
        total_time = sum(s.total_time for s in self.stats.values() if s.category == 'function')

        # çƒ­ç‚¹å‡½æ•°è¯†åˆ«
        hotspots = []
        for key, s in self.stats.items():
            if s.category == 'function':
                time_pct = s.total_time / total_time if total_time > 0 else 0
                if time_pct >= self.hotspot_threshold:
                    hotspots.append({
                        'name': s.name,
                        'call_count': s.call_count,
                        'total_time': round(s.total_time, 4),
                        'time_percentage': round(time_pct * 100, 2),
                        'avg_time': round(s.avg_time, 4),
                    })
        hotspots.sort(key=lambda x: x['total_time'], reverse=True)

        # è°ƒç”¨é¢‘ç‡æœ€é«˜çš„å‡½æ•°
        most_called = sorted(
            [{'name': s.name, 'call_count': s.call_count, 'total_time': round(s.total_time, 4)}
             for s in self.stats.values() if s.category == 'function'],
            key=lambda x: x['call_count'],
            reverse=True
        )[:20]

        # è°ƒç”¨è€…-è¢«è°ƒç”¨è€…å…³ç³»ç»Ÿè®¡
        caller_callee_pairs = defaultdict(int)
        for record in self.function_calls:
            if record.caller and record.caller != "unknown":
                pair = f"{record.caller} -> {record.func_name}"
                caller_callee_pairs[pair] += 1

        top_call_pairs = sorted(
            [{'pair': k, 'count': v} for k, v in caller_callee_pairs.items()],
            key=lambda x: x['count'],
            reverse=True
        )[:30]

        # è°ƒç”¨å›¾æ‘˜è¦
        call_graph_summary = [node.to_dict() for node in self.call_graph.values()
                              if node.call_count > 0][:50]

        return {
            'total_function_time': round(total_time, 4),
            'total_function_calls': len(self.function_calls),
            'unique_functions': len([s for s in self.stats.values() if s.category == 'function']),
            'hotspots': hotspots,
            'most_called': most_called,
            'top_call_pairs': top_call_pairs,
            'call_graph_summary': call_graph_summary,
        }

    def get_hotspot_functions(self, top_n: int = 10) -> List[Dict]:
        """è·å–çƒ­ç‚¹å‡½æ•°åˆ—è¡¨"""
        total_time = sum(s.total_time for s in self.stats.values() if s.category == 'function')

        result = []
        for key, s in self.stats.items():
            if s.category == 'function':
                time_pct = s.total_time / total_time if total_time > 0 else 0
                result.append({
                    'name': s.name,
                    'call_count': s.call_count,
                    'total_time': round(s.total_time, 4),
                    'avg_time': round(s.avg_time, 4),
                    'time_percentage': round(time_pct * 100, 2),
                    'is_hotspot': time_pct >= self.hotspot_threshold,
                })
        result.sort(key=lambda x: x['total_time'], reverse=True)
        return result[:top_n]

    def get_summary(self) -> Dict:
        """è·å–æ±‡æ€»ç»Ÿè®¡"""
        step_total = sum(s.total_time for s in self.stats.values() if s.category == 'step')
        func_total = sum(s.total_time for s in self.stats.values() if s.category == 'function')
        model_total = sum(s.total_time for s in self.stats.values() if s.category == 'model')

        # è®¡ç®—æ¨¡å‹æ¨ç†è¯¦ç»†æ±‡æ€»
        total_samples = sum(s.total_samples for s in self.model_stats.values())
        avg_throughput = total_samples / model_total if model_total > 0 else 0

        return {
            'session_info': self.session_info,
            'total_records': len(self.records),
            'step_count': len([s for s in self.stats.values() if s.category == 'step']),
            'step_total_time': round(step_total, 4),
            'function_count': len([s for s in self.stats.values() if s.category == 'function']),
            'function_total_time': round(func_total, 4),
            'function_call_count': len(self.function_calls),
            'model_count': len([s for s in self.stats.values() if s.category == 'model']),
            'model_total_time': round(model_total, 4),
            'model_total_samples': total_samples,
            'model_avg_throughput': round(avg_throughput, 2),
            'hotspot_count': len(self.get_hotspot_functions()),
        }

    def generate_report(self, output_path: Optional[str] = None) -> Dict:
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        self.end_session()

        report = {
            'summary': self.get_summary(),
            'steps': self.get_step_stats(),
            'functions': self.get_function_stats(),
            'models': self.get_model_stats(),
            'models_detailed': self.get_model_detailed_stats(),
            'function_analysis': self.get_function_call_analysis(),
            'hotspots': self.get_hotspot_functions(20),
            'timeline': [
                {
                    'name': r.name,
                    'category': r.category,
                    'duration': round(r.duration, 4),
                    'timestamp': r.timestamp,
                    **r.extra_info
                }
                for r in self.records
            ]
        }

        if output_path:
            os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")

        return report

    def print_summary(self):
        """æ‰“å°ç®€è¦ç»Ÿè®¡åˆ°æ§åˆ¶å°"""
        print("\n" + "="*70)
        print("æ€§èƒ½åˆ†ææŠ¥å‘Š")
        print("="*70)

        summary = self.get_summary()
        print(f"\nä¼šè¯ä¿¡æ¯:")
        print(f"  å¼€å§‹æ—¶é—´: {summary['session_info'].get('start_time', 'N/A')}")
        print(f"  æ€»è€—æ—¶: {summary['session_info'].get('total_duration', 0):.2f}ç§’")

        print(f"\næ­¥éª¤ç»Ÿè®¡ (å…±{summary['step_count']}ä¸ªæ­¥éª¤):")
        print("-"*70)
        print(f"{'æ­¥éª¤åç§°':<30} {'æ¬¡æ•°':>6} {'æ€»æ—¶é—´(ç§’)':>12} {'å¹³å‡(ç§’)':>10}")
        print("-"*70)
        for s in self.get_step_stats():
            print(f"{s['name']:<30} {s['call_count']:>6} {s['total_time']:>12.4f} {s['avg_time']:>10.4f}")

        print(f"\næ¨¡å‹æ¨ç†ç»Ÿè®¡ (å…±{summary['model_count']}ä¸ªæ¨¡å‹):")
        print("-"*70)
        print(f"{'æ¨¡å‹åç§°':<20} {'æ¬¡æ•°':>6} {'æ€»æ—¶é—´(ç§’)':>10} {'å¹³å‡(ç§’)':>8} {'æ ·æœ¬æ•°':>8} {'ååé‡':>10}")
        print("-"*70)
        for m in self.get_model_detailed_stats():
            print(f"{m['name']:<20} {m['call_count']:>6} {m['total_time']:>10.4f} "
                  f"{m['avg_time']:>8.4f} {m['total_samples']:>8} {m['throughput']:>8.2f}/s")

        # æ˜¾ç¤ºæ¨¡å‹è€—æ—¶åˆ†è§£
        detailed_stats = self.get_model_detailed_stats()
        if detailed_stats:
            print(f"\næ¨¡å‹è€—æ—¶åˆ†è§£:")
            print("-"*70)
            print(f"{'æ¨¡å‹åç§°':<20} {'é¢„å¤„ç†':>12} {'æ¨ç†':>12} {'åå¤„ç†':>12} {'å…¶ä»–':>12}")
            print("-"*70)
            for m in detailed_stats:
                other_pct = 100 - m['preprocess_pct'] - m['inference_pct'] - m['postprocess_pct']
                print(f"{m['name']:<20} {m['preprocess_pct']:>10.1f}% {m['inference_pct']:>10.1f}% "
                      f"{m['postprocess_pct']:>10.1f}% {other_pct:>10.1f}%")

        print(f"\nçƒ­ç‚¹å‡½æ•° (Top 10):")
        print("-"*70)
        print(f"{'å‡½æ•°åç§°':<40} {'æ¬¡æ•°':>6} {'æ€»æ—¶é—´(ç§’)':>10} {'å æ¯”':>8}")
        print("-"*70)
        for f in self.get_hotspot_functions(10):
            name = f['name'][:38] + '..' if len(f['name']) > 40 else f['name']
            hotspot_mark = "ğŸ”¥" if f['is_hotspot'] else "  "
            print(f"{hotspot_mark}{name:<38} {f['call_count']:>6} {f['total_time']:>10.4f} {f['time_percentage']:>6.1f}%")

        print(f"\nå‡½æ•°è°ƒç”¨ç»Ÿè®¡ (Top 20):")
        print("-"*70)
        print(f"{'å‡½æ•°åç§°':<40} {'æ¬¡æ•°':>6} {'æ€»æ—¶é—´(ç§’)':>12}")
        print("-"*70)
        for f in self.get_function_stats()[:20]:
            name = f['name'][:38] + '..' if len(f['name']) > 40 else f['name']
            print(f"{name:<40} {f['call_count']:>6} {f['total_time']:>12.4f}")

        print("="*70 + "\n")


# å…¨å±€å•ä¾‹
profiler = PerformanceProfiler()


@contextmanager
def step_timer(step_name: str, extra_info: Optional[Dict[str, Any]] = None):
    """æ­¥éª¤è®¡æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨

    Args:
        step_name: æ­¥éª¤åç§°
        extra_info: é¢å¤–ä¿¡æ¯

    Usage:
        with step_timer("PDFé¢„å¤„ç†"):
            preprocess()
    """
    start = time.time()
    try:
        yield
    finally:
        duration = time.time() - start
        profiler.record(step_name, duration, 'step', extra_info)
        print(f"[Profiler] æ­¥éª¤ '{step_name}' å®Œæˆ, è€—æ—¶: {duration:.4f}ç§’")


@contextmanager
def model_timer(model_name: str, extra_info: Optional[Dict[str, Any]] = None):
    """æ¨¡å‹æ¨ç†è®¡æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨

    Args:
        model_name: æ¨¡å‹åç§° (å¦‚ DETR, YOLO, DBNet, SVTR)
        extra_info: é¢å¤–ä¿¡æ¯ (å¦‚è¾“å…¥å°ºå¯¸, batch sizeç­‰)

    Usage:
        with model_timer("DETR", {"input_size": "640x640"}):
            model.predict(image)
    """
    start = time.time()
    try:
        yield
    finally:
        duration = time.time() - start
        profiler.record(model_name, duration, 'model', extra_info)


@contextmanager
def model_timer_detailed(model_name: str, batch_size: int = 1,
                         input_size: str = None,
                         extra_info: Optional[Dict[str, Any]] = None):
    """æ¨¡å‹æ¨ç†è¯¦ç»†è®¡æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆæ”¯æŒåˆ†é˜¶æ®µè®¡æ—¶ï¼‰

    Args:
        model_name: æ¨¡å‹åç§° (å¦‚ DETR, YOLO, DBNet, SVTR)
        batch_size: æ‰¹æ¬¡å¤§å°
        input_size: è¾“å…¥å°ºå¯¸æè¿° (å¦‚ "640x640")
        extra_info: é¢å¤–ä¿¡æ¯

    Usage:
        with model_timer_detailed("DETR", batch_size=1, input_size="640x640") as timer:
            timer.mark_preprocess_start()
            preprocessed = preprocess(image)
            timer.mark_preprocess_end()

            timer.mark_inference_start()
            output = model.predict(preprocessed)
            timer.mark_inference_end()

            timer.mark_postprocess_start()
            result = postprocess(output)
            timer.mark_postprocess_end()
    """
    timer = DetailedModelTimer(model_name, batch_size, input_size, extra_info)
    timer.start()
    try:
        yield timer
    finally:
        timer.stop()


class DetailedModelTimer:
    """è¯¦ç»†æ¨¡å‹è®¡æ—¶å™¨ï¼Œæ”¯æŒé¢„å¤„ç†/æ¨ç†/åå¤„ç†åˆ†é˜¶æ®µè®¡æ—¶"""

    def __init__(self, model_name: str, batch_size: int = 1,
                 input_size: str = None, extra_info: Optional[Dict[str, Any]] = None):
        self.model_name = model_name
        self.batch_size = batch_size
        self.input_size = input_size
        self.extra_info = extra_info or {}

        self._start_time: Optional[float] = None
        self._end_time: Optional[float] = None

        self._preprocess_start: Optional[float] = None
        self._preprocess_end: Optional[float] = None
        self._inference_start: Optional[float] = None
        self._inference_end: Optional[float] = None
        self._postprocess_start: Optional[float] = None
        self._postprocess_end: Optional[float] = None

    def start(self):
        self._start_time = time.time()

    def stop(self):
        self._end_time = time.time()
        self._record()

    def mark_preprocess_start(self):
        self._preprocess_start = time.time()

    def mark_preprocess_end(self):
        self._preprocess_end = time.time()

    def mark_inference_start(self):
        self._inference_start = time.time()

    def mark_inference_end(self):
        self._inference_end = time.time()

    def mark_postprocess_start(self):
        self._postprocess_start = time.time()

    def mark_postprocess_end(self):
        self._postprocess_end = time.time()

    def _record(self):
        if self._start_time is None or self._end_time is None:
            return

        total_duration = self._end_time - self._start_time
        preprocess_time = 0.0
        inference_time = 0.0
        postprocess_time = 0.0

        if self._preprocess_start and self._preprocess_end:
            preprocess_time = self._preprocess_end - self._preprocess_start
        if self._inference_start and self._inference_end:
            inference_time = self._inference_end - self._inference_start
        if self._postprocess_start and self._postprocess_end:
            postprocess_time = self._postprocess_end - self._postprocess_start

        profiler.record_model_inference(
            model_name=self.model_name,
            duration=total_duration,
            batch_size=self.batch_size,
            preprocess_time=preprocess_time,
            inference_time=inference_time,
            postprocess_time=postprocess_time,
            input_size=self.input_size,
            extra_info=self.extra_info
        )


def func_timer(func=None, *, name: str = None):
    """å‡½æ•°è®¡æ—¶è£…é¥°å™¨

    Args:
        func: è¢«è£…é¥°çš„å‡½æ•°
        name: è‡ªå®šä¹‰åç§°, é»˜è®¤ä½¿ç”¨å‡½æ•°å

    Usage:
        @func_timer
        def my_function():
            pass

        @func_timer(name="è‡ªå®šä¹‰åç§°")
        def another_function():
            pass
    """
    def decorator(fn):
        fn_name = name or f"{fn.__module__}.{fn.__qualname__}"

        @wraps(fn)
        def wrapper(*args, **kwargs):
            start = time.time()
            try:
                return fn(*args, **kwargs)
            finally:
                duration = time.time() - start
                profiler.record(fn_name, duration, 'function')

        return wrapper

    if func is not None:
        return decorator(func)
    return decorator


def call_tracker(func=None, *, name: str = None, track_args: bool = False):
    """å¸¦è°ƒç”¨æ ˆè¿½è¸ªçš„å‡½æ•°è®¡æ—¶è£…é¥°å™¨

    Args:
        func: è¢«è£…é¥°çš„å‡½æ•°
        name: è‡ªå®šä¹‰åç§°, é»˜è®¤ä½¿ç”¨å‡½æ•°å
        track_args: æ˜¯å¦è®°å½•å‚æ•°ä¿¡æ¯

    Usage:
        @call_tracker
        def my_function():
            pass

        @call_tracker(track_args=True)
        def another_function(x, y):
            pass
    """
    def decorator(fn):
        fn_name = name or f"{fn.__module__}.{fn.__qualname__}"

        @wraps(fn)
        def wrapper(*args, **kwargs):
            # è·å–è°ƒç”¨è€…ä¿¡æ¯
            caller = profiler.get_current_caller()
            call_stack = profiler.get_call_stack()

            # è®°å½•å‚æ•°ä¿¡æ¯
            args_info = ""
            if track_args:
                args_repr = [repr(a)[:50] for a in args[:3]]  # åªè®°å½•å‰3ä¸ªå‚æ•°
                kwargs_repr = [f"{k}={repr(v)[:30]}" for k, v in list(kwargs.items())[:3]]
                args_info = ", ".join(args_repr + kwargs_repr)

            # å…¥æ ˆ
            profiler.push_call_stack(fn_name)

            start = time.time()
            try:
                return fn(*args, **kwargs)
            finally:
                duration = time.time() - start
                # è®°å½•å‡½æ•°è°ƒç”¨
                profiler.record_function_call(
                    func_name=fn_name,
                    duration=duration,
                    caller=caller,
                    call_stack=call_stack,
                    args_info=args_info
                )
                # å‡ºæ ˆ
                profiler.pop_call_stack()

        return wrapper

    if func is not None:
        return decorator(func)
    return decorator


def auto_profile_class(cls):
    """ç±»è£…é¥°å™¨ï¼šè‡ªåŠ¨ä¸ºç±»çš„æ‰€æœ‰å…¬å…±æ–¹æ³•æ·»åŠ è®¡æ—¶

    Usage:
        @auto_profile_class
        class MyModel:
            def predict(self, x):
                pass
    """
    for attr_name in dir(cls):
        if attr_name.startswith('_'):
            continue
        attr = getattr(cls, attr_name)
        if callable(attr):
            setattr(cls, attr_name, call_tracker(attr, name=f"{cls.__name__}.{attr_name}"))
    return cls


class TimerContext:
    """å¯å¤ç”¨çš„è®¡æ—¶å™¨ç±»

    Usage:
        timer = TimerContext("æ¨¡å‹åŠ è½½")
        timer.start()
        load_model()
        timer.stop()
        print(f"è€—æ—¶: {timer.elapsed}ç§’")
    """

    def __init__(self, name: str, category: str = 'step', auto_record: bool = True):
        self.name = name
        self.category = category
        self.auto_record = auto_record
        self._start: Optional[float] = None
        self._elapsed: float = 0.0

    def start(self):
        self._start = time.time()
        return self

    def stop(self):
        if self._start is not None:
            self._elapsed = time.time() - self._start
            if self.auto_record:
                profiler.record(self.name, self._elapsed, self.category)
            self._start = None
        return self._elapsed

    @property
    def elapsed(self) -> float:
        if self._start is not None:
            return time.time() - self._start
        return self._elapsed

    def __enter__(self):
        self.start()
        return self

    def __exit__(self, *args):
        self.stop()


def generate_html_report(report: Dict, output_path: str):
    """ç”ŸæˆHTMLæ ¼å¼çš„å¯è§†åŒ–æŠ¥å‘Š"""

    html_template = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PackageWizard æ€§èƒ½åˆ†ææŠ¥å‘Š</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: 'Segoe UI', Arial, sans-serif; background: #f5f7fa; color: #333; line-height: 1.6; }}
        .container {{ max-width: 1400px; margin: 0 auto; padding: 20px; }}
        h1 {{ color: #2c3e50; margin-bottom: 20px; padding-bottom: 10px; border-bottom: 3px solid #3498db; }}
        h2 {{ color: #34495e; margin: 30px 0 15px; display: flex; align-items: center; gap: 10px; }}
        h3 {{ color: #5d6d7e; margin: 20px 0 10px; font-size: 16px; }}
        .summary-cards {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(180px, 1fr)); gap: 15px; margin-bottom: 30px; }}
        .card {{ background: white; border-radius: 10px; padding: 20px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); transition: transform 0.2s; }}
        .card:hover {{ transform: translateY(-2px); }}
        .card-title {{ font-size: 13px; color: #7f8c8d; margin-bottom: 5px; text-transform: uppercase; letter-spacing: 0.5px; }}
        .card-value {{ font-size: 28px; font-weight: bold; color: #2c3e50; }}
        .card-unit {{ font-size: 14px; color: #95a5a6; }}
        .card-subtitle {{ font-size: 12px; color: #95a5a6; margin-top: 5px; }}
        .card.step {{ border-left: 4px solid #3498db; }}
        .card.model {{ border-left: 4px solid #e74c3c; }}
        .card.function {{ border-left: 4px solid #27ae60; }}
        .card.hotspot {{ border-left: 4px solid #f39c12; }}
        table {{ width: 100%; background: white; border-radius: 10px; overflow: hidden; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-bottom: 30px; }}
        th, td {{ padding: 12px 15px; text-align: left; border-bottom: 1px solid #ecf0f1; }}
        th {{ background: #34495e; color: white; font-weight: 600; font-size: 13px; text-transform: uppercase; }}
        tr:hover {{ background: #f8f9fa; }}
        tr:last-child td {{ border-bottom: none; }}
        .bar-container {{ width: 100%; background: #ecf0f1; border-radius: 3px; height: 8px; }}
        .bar {{ height: 100%; border-radius: 3px; transition: width 0.3s; }}
        .bar.step {{ background: linear-gradient(90deg, #3498db, #2980b9); }}
        .bar.model {{ background: linear-gradient(90deg, #e74c3c, #c0392b); }}
        .bar.function {{ background: linear-gradient(90deg, #27ae60, #1e8449); }}
        .bar.hotspot {{ background: linear-gradient(90deg, #f39c12, #d68910); }}
        .section {{ margin-bottom: 40px; }}
        .timestamp {{ color: #7f8c8d; font-size: 12px; text-align: center; margin-top: 30px; }}
        .hotspot-badge {{ background: #f39c12; color: white; padding: 2px 8px; border-radius: 10px; font-size: 11px; margin-left: 5px; }}
        .grid-2 {{ display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px; }}
        .phase-bar {{ display: flex; height: 24px; border-radius: 4px; overflow: hidden; margin: 5px 0; }}
        .phase-bar div {{ display: flex; align-items: center; justify-content: center; font-size: 11px; color: white; }}
        .phase-preprocess {{ background: #3498db; }}
        .phase-inference {{ background: #e74c3c; }}
        .phase-postprocess {{ background: #27ae60; }}
        .phase-other {{ background: #95a5a6; }}
        .legend {{ display: flex; gap: 20px; margin: 10px 0; font-size: 12px; }}
        .legend-item {{ display: flex; align-items: center; gap: 5px; }}
        .legend-color {{ width: 12px; height: 12px; border-radius: 2px; }}
        .tabs {{ display: flex; gap: 5px; margin-bottom: 20px; }}
        .tab {{ padding: 10px 20px; background: #ecf0f1; border: none; border-radius: 5px 5px 0 0; cursor: pointer; font-size: 14px; }}
        .tab.active {{ background: white; font-weight: 600; }}
        .tab-content {{ display: none; }}
        .tab-content.active {{ display: block; }}
        @media (max-width: 768px) {{
            .grid-2 {{ grid-template-columns: 1fr; }}
            .summary-cards {{ grid-template-columns: repeat(2, 1fr); }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>PackageWizard æ€§èƒ½åˆ†ææŠ¥å‘Š</h1>

        <div class="summary-cards">
            <div class="card step">
                <div class="card-title">æ­¥éª¤æ€»æ•°</div>
                <div class="card-value">{step_count}</div>
            </div>
            <div class="card step">
                <div class="card-title">æ­¥éª¤æ€»è€—æ—¶</div>
                <div class="card-value">{step_time:.2f}<span class="card-unit">ç§’</span></div>
            </div>
            <div class="card model">
                <div class="card-title">æ¨¡å‹æ¨ç†æ¬¡æ•°</div>
                <div class="card-value">{model_count}</div>
            </div>
            <div class="card model">
                <div class="card-title">æ¨¡å‹æ¨ç†æ€»è€—æ—¶</div>
                <div class="card-value">{model_time:.2f}<span class="card-unit">ç§’</span></div>
            </div>
            <div class="card model">
                <div class="card-title">å¹³å‡ååé‡</div>
                <div class="card-value">{model_throughput:.1f}<span class="card-unit">æ ·æœ¬/ç§’</span></div>
            </div>
            <div class="card function">
                <div class="card-title">å‡½æ•°è°ƒç”¨æ•°</div>
                <div class="card-value">{func_count}</div>
            </div>
            <div class="card hotspot">
                <div class="card-title">çƒ­ç‚¹å‡½æ•°</div>
                <div class="card-value">{hotspot_count}</div>
                <div class="card-subtitle">&gt;5%æ€»è€—æ—¶</div>
            </div>
            <div class="card function">
                <div class="card-title">æ€»è¿è¡Œæ—¶é—´</div>
                <div class="card-value">{total_time:.2f}<span class="card-unit">ç§’</span></div>
            </div>
        </div>

        <div class="section">
            <h2>æ­¥éª¤è€—æ—¶ç»Ÿè®¡</h2>
            <table>
                <thead>
                    <tr>
                        <th>æ­¥éª¤åç§°</th>
                        <th>è°ƒç”¨æ¬¡æ•°</th>
                        <th>æ€»è€—æ—¶(ç§’)</th>
                        <th>å¹³å‡è€—æ—¶(ç§’)</th>
                        <th>å æ¯”</th>
                    </tr>
                </thead>
                <tbody>
                    {step_rows}
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>æ¨¡å‹æ¨ç†è¯¦ç»†ç»Ÿè®¡</h2>
            <table>
                <thead>
                    <tr>
                        <th>æ¨¡å‹åç§°</th>
                        <th>è°ƒç”¨æ¬¡æ•°</th>
                        <th>æ ·æœ¬æ•°</th>
                        <th>æ€»è€—æ—¶(ç§’)</th>
                        <th>å¹³å‡(ç§’)</th>
                        <th>ååé‡</th>
                        <th>è€—æ—¶åˆ†è§£</th>
                    </tr>
                </thead>
                <tbody>
                    {model_detailed_rows}
                </tbody>
            </table>
            <div class="legend">
                <div class="legend-item"><div class="legend-color phase-preprocess"></div>é¢„å¤„ç†</div>
                <div class="legend-item"><div class="legend-color phase-inference"></div>æ¨ç†</div>
                <div class="legend-item"><div class="legend-color phase-postprocess"></div>åå¤„ç†</div>
                <div class="legend-item"><div class="legend-color phase-other"></div>å…¶ä»–</div>
            </div>
        </div>

        <div class="section">
            <h2>çƒ­ç‚¹å‡½æ•°åˆ†æ</h2>
            <p style="color: #7f8c8d; margin-bottom: 15px;">ä»¥ä¸‹å‡½æ•°å ç”¨äº†è¶…è¿‡5%çš„æ€»æ‰§è¡Œæ—¶é—´ï¼Œæ˜¯æ€§èƒ½ä¼˜åŒ–çš„é‡ç‚¹ç›®æ ‡</p>
            <table>
                <thead>
                    <tr>
                        <th>å‡½æ•°åç§°</th>
                        <th>è°ƒç”¨æ¬¡æ•°</th>
                        <th>æ€»è€—æ—¶(ç§’)</th>
                        <th>å¹³å‡è€—æ—¶(ç§’)</th>
                        <th>æ—¶é—´å æ¯”</th>
                    </tr>
                </thead>
                <tbody>
                    {hotspot_rows}
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>å‡½æ•°è°ƒç”¨è€—æ—¶ç»Ÿè®¡ (Top 30)</h2>
            <table>
                <thead>
                    <tr>
                        <th>å‡½æ•°åç§°</th>
                        <th>è°ƒç”¨æ¬¡æ•°</th>
                        <th>æ€»è€—æ—¶(ç§’)</th>
                        <th>å¹³å‡è€—æ—¶(ç§’)</th>
                        <th>å æ¯”</th>
                    </tr>
                </thead>
                <tbody>
                    {func_rows}
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>é«˜é¢‘è°ƒç”¨å‡½æ•° (Top 20)</h2>
            <table>
                <thead>
                    <tr>
                        <th>å‡½æ•°åç§°</th>
                        <th>è°ƒç”¨æ¬¡æ•°</th>
                        <th>æ€»è€—æ—¶(ç§’)</th>
                    </tr>
                </thead>
                <tbody>
                    {most_called_rows}
                </tbody>
            </table>
        </div>

        <p class="timestamp">æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {timestamp}</p>
    </div>
</body>
</html>
    """

    summary = report['summary']
    step_time = summary.get('step_total_time', 0)
    model_time = summary.get('model_total_time', 0)
    func_time = summary.get('function_total_time', 0)
    total_time = summary.get('session_info', {}).get('total_duration', step_time + model_time)
    model_throughput = summary.get('model_avg_throughput', 0)
    hotspot_count = summary.get('hotspot_count', 0)

    def make_rows(items, category, max_time):
        rows = []
        for item in items:
            pct = (item['total_time'] / max_time * 100) if max_time > 0 else 0
            rows.append(f"""
                <tr>
                    <td>{item['name']}</td>
                    <td>{item['call_count']}</td>
                    <td>{item['total_time']:.4f}</td>
                    <td>{item['avg_time']:.4f}</td>
                    <td>
                        <div class="bar-container">
                            <div class="bar {category}" style="width: {min(pct, 100)}%"></div>
                        </div>
                        {pct:.1f}%
                    </td>
                </tr>
            """)
        return '\n'.join(rows)

    def make_model_detailed_rows(items):
        rows = []
        for item in items:
            pre_pct = item.get('preprocess_pct', 0)
            inf_pct = item.get('inference_pct', 0)
            post_pct = item.get('postprocess_pct', 0)
            other_pct = max(0, 100 - pre_pct - inf_pct - post_pct)

            phase_bar = f"""
                <div class="phase-bar">
                    <div class="phase-preprocess" style="width: {pre_pct}%">{pre_pct:.0f}%</div>
                    <div class="phase-inference" style="width: {inf_pct}%">{inf_pct:.0f}%</div>
                    <div class="phase-postprocess" style="width: {post_pct}%">{post_pct:.0f}%</div>
                    <div class="phase-other" style="width: {other_pct}%">{other_pct:.0f}%</div>
                </div>
            """

            rows.append(f"""
                <tr>
                    <td>{item['name']}</td>
                    <td>{item['call_count']}</td>
                    <td>{item.get('total_samples', item['call_count'])}</td>
                    <td>{item['total_time']:.4f}</td>
                    <td>{item['avg_time']:.4f}</td>
                    <td>{item.get('throughput', 0):.2f}/s</td>
                    <td style="min-width: 200px">{phase_bar}</td>
                </tr>
            """)
        return '\n'.join(rows)

    def make_hotspot_rows(items):
        rows = []
        for item in items:
            is_hotspot = item.get('is_hotspot', False)
            badge = '<span class="hotspot-badge">HOTSPOT</span>' if is_hotspot else ''
            pct = item.get('time_percentage', 0)
            rows.append(f"""
                <tr>
                    <td>{item['name']}{badge}</td>
                    <td>{item['call_count']}</td>
                    <td>{item['total_time']:.4f}</td>
                    <td>{item['avg_time']:.4f}</td>
                    <td>
                        <div class="bar-container">
                            <div class="bar hotspot" style="width: {min(pct, 100)}%"></div>
                        </div>
                        {pct:.1f}%
                    </td>
                </tr>
            """)
        return '\n'.join(rows)

    def make_most_called_rows(items):
        rows = []
        for item in items:
            rows.append(f"""
                <tr>
                    <td>{item['name']}</td>
                    <td>{item['call_count']}</td>
                    <td>{item['total_time']:.4f}</td>
                </tr>
            """)
        return '\n'.join(rows)

    step_rows = make_rows(report.get('steps', []), 'step', step_time)

    # ä½¿ç”¨è¯¦ç»†çš„æ¨¡å‹ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
    models_detailed = report.get('models_detailed', report.get('models', []))
    model_detailed_rows = make_model_detailed_rows(models_detailed)

    func_rows = make_rows(report.get('functions', [])[:30], 'function', func_time)

    # çƒ­ç‚¹å‡½æ•°
    hotspots = report.get('hotspots', [])
    hotspot_rows = make_hotspot_rows(hotspots)

    # é«˜é¢‘è°ƒç”¨å‡½æ•°
    func_analysis = report.get('function_analysis', {})
    most_called = func_analysis.get('most_called', [])[:20]
    most_called_rows = make_most_called_rows(most_called)

    func_calls = summary.get('function_call_count', sum(f['call_count'] for f in report.get('functions', [])))

    html = html_template.format(
        step_count=summary.get('step_count', 0),
        step_time=step_time,
        model_count=sum(m['call_count'] for m in report.get('models', [])),
        model_time=model_time,
        model_throughput=model_throughput,
        func_count=func_calls,
        hotspot_count=hotspot_count,
        total_time=total_time,
        step_rows=step_rows or '<tr><td colspan="5">æš‚æ— æ•°æ®</td></tr>',
        model_detailed_rows=model_detailed_rows or '<tr><td colspan="7">æš‚æ— æ•°æ®</td></tr>',
        hotspot_rows=hotspot_rows or '<tr><td colspan="5">æš‚æ— çƒ­ç‚¹å‡½æ•°</td></tr>',
        func_rows=func_rows or '<tr><td colspan="5">æš‚æ— æ•°æ®</td></tr>',
        most_called_rows=most_called_rows or '<tr><td colspan="3">æš‚æ— æ•°æ®</td></tr>',
        timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    )

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html)
    print(f"HTMLæŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    profiler.start_session({'test': True})

    with step_timer("æµ‹è¯•æ­¥éª¤1"):
        time.sleep(0.1)

    with step_timer("æµ‹è¯•æ­¥éª¤2"):
        time.sleep(0.2)

    # æµ‹è¯•ç®€å•çš„æ¨¡å‹è®¡æ—¶
    with model_timer("DETR"):
        time.sleep(0.05)

    with model_timer("YOLO"):
        time.sleep(0.03)

    # æµ‹è¯•è¯¦ç»†çš„æ¨¡å‹è®¡æ—¶ï¼ˆåŒ…å«åˆ†é˜¶æ®µï¼‰
    with model_timer_detailed("DBNet", batch_size=2, input_size="640x480") as timer:
        timer.mark_preprocess_start()
        time.sleep(0.01)  # æ¨¡æ‹Ÿé¢„å¤„ç†
        timer.mark_preprocess_end()

        timer.mark_inference_start()
        time.sleep(0.03)  # æ¨¡æ‹Ÿæ¨ç†
        timer.mark_inference_end()

        timer.mark_postprocess_start()
        time.sleep(0.005)  # æ¨¡æ‹Ÿåå¤„ç†
        timer.mark_postprocess_end()

    # æµ‹è¯•å‡½æ•°è®¡æ—¶è£…é¥°å™¨
    @func_timer
    def test_func():
        time.sleep(0.01)

    for _ in range(5):
        test_func()

    # æµ‹è¯•å¸¦è°ƒç”¨æ ˆè¿½è¸ªçš„è£…é¥°å™¨
    @call_tracker
    def outer_func():
        time.sleep(0.01)
        inner_func()

    @call_tracker
    def inner_func():
        time.sleep(0.005)

    for _ in range(3):
        outer_func()

    profiler.print_summary()
    report = profiler.generate_report("test_performance_report.json")
    generate_html_report(report, "test_performance_report.html")
